{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditi230/Iris-Classification/blob/main/final_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLBxt5FvT1Ll"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIpXZX26Caza"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from pandas import DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9EDdJSEG8M_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a6fb3805-1f05-47a7-fd9c-1b985629e75b"
      },
      "source": [
        "df=pd.read_csv(\"/content/Iris.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqKPcITsC96"
      },
      "source": [
        "\n",
        "def set_value(row_number, assigned_value): \n",
        "\treturn assigned_value[row_number] \n",
        " \n",
        "event_dictionary ={'Iris-setosa' : 1, 'Iris-versicolor' : 2, 'Iris-virginica' : 3} \n",
        "\n",
        "df['Type'] = df['Species'].apply(set_value, args =(event_dictionary, )) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qap91yWNHDFL"
      },
      "source": [
        "target = df[\"Type\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht0aN3hMHPwG"
      },
      "source": [
        "features = df.drop([\"Id\",\"Species\",\"Type\"],axis=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTMzssvfHWOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a626bdb0-c1aa-456c-c4ec-a5a96b4f8da8"
      },
      "source": [
        "type(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4pQnCJ6cPiJ"
      },
      "source": [
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNcx9BaFHgfY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc825502-b075-4856-c41a-6d5db6fb9162"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEtR57bRHoJJ"
      },
      "source": [
        "Specifying Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihI0bh6uHq18"
      },
      "source": [
        "import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6P2s_aF2RK8"
      },
      "source": [
        "#predictors = df.drop([\"Type\"], axis=1).values\n",
        "#target=to_categorical(df.Type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITaljKgQIC4G"
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA2cPoujItdG"
      },
      "source": [
        "model.add(Dense(10,activation=\"relu\",input_shape=(4,)))\n",
        "model.add(Dense(10,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "model.add(Dense(3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxPyJJfbJ22C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b6852e9-7edc-40d6-ed69-e51a21ac2063"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
        "model.loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mean_squared_error'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V2SPgc-VgCj"
      },
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#enc = LabelEncoder()\n",
        "#enc.fit(df['Species'])\n",
        "#df['Species'] = enc.transform(df['Species'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USYZz_LYWCsY"
      },
      "source": [
        "#target=df[\"Species\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvEVL7pjWfgz"
      },
      "source": [
        "#df1 = DataFrame(df,columns=['Id','Species'])\n",
        "#df1.plot(x ='Id', y='Species', kind = 'scatter')\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-INFxq-L10L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "922df4e5-ebcc-40ab-b53e-8045919b397e"
      },
      "source": [
        "model.fit(features,target,epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.2411\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 5.9545\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 5.5507\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 5.0588\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 4.6045\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 4.2906\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 4.1037\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 3.9903\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.9120\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.8492\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.7972\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.7511\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.7093\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.6682\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.6288\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 3.5913\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.5548\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.5189\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.4837\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.4499\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.4152\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.3819\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 3.3496\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.3162\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.2847\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.2530\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.2216\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 3.1911\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.1604\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.1302\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.1014\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.0713\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.0425\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.0142\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.9853\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.9574\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.9302\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 2.9024\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 2.8755\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.8481\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.8221\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.7959\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.7694\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.7436\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.7183\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.6932\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.6680\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.6441\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.6189\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.5950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd897caba58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "999bNWBKMMd8"
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save('my_model.h5')\n",
        "my_model=load_model('my_model.h5')\n",
        "predictions = my_model.predict(features)\n",
        "probability_true=predictions[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQWXgeRa7Kw0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "55621b09-048b-4422-d03e-b3eaa3b8a51f"
      },
      "source": [
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 22        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 9         \n",
            "=================================================================\n",
            "Total params: 191\n",
            "Trainable params: 191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHxh8t_C9id8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b182b5a-f8fc-4318-f3e2-492c1a73b930"
      },
      "source": [
        "from keras import backend as K\n",
        "outputs = []\n",
        "for layer in model.layers:\n",
        "    keras_function = K.function([model.input], [layer.output])\n",
        "    outputs.append(keras_function([features, 1]))\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[2.8902047 , 0.        , 0.37075755, ..., 0.10027384, 3.5162039 ,\n",
            "        0.        ],\n",
            "       [2.6077297 , 0.        , 0.3385701 , ..., 0.        , 3.2487087 ,\n",
            "        0.        ],\n",
            "       [2.6614435 , 0.        , 0.3415137 , ..., 0.07728653, 3.2259374 ,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [1.7906524 , 0.        , 1.0298977 , ..., 0.81599677, 5.171437  ,\n",
            "        0.        ],\n",
            "       [1.797697  , 0.        , 1.1452864 , ..., 1.1510159 , 5.26869   ,\n",
            "        0.        ],\n",
            "       [1.5986123 , 0.        , 0.9375856 , ..., 1.0714191 , 5.0353937 ,\n",
            "        0.        ]], dtype=float32)], [array([[0.        , 2.2634096 , 0.39402655, ..., 3.9045334 , 0.3005919 ,\n",
            "        0.        ],\n",
            "       [0.        , 2.2031658 , 0.41290295, ..., 3.72286   , 0.25286183,\n",
            "        0.        ],\n",
            "       [0.        , 2.103579  , 0.3723426 , ..., 3.6078792 , 0.26766437,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 2.8427644 , 1.4479736 , ..., 5.853744  , 1.247656  ,\n",
            "        0.        ],\n",
            "       [0.        , 2.6724293 , 1.4975705 , ..., 5.8646436 , 1.4854661 ,\n",
            "        0.        ],\n",
            "       [0.        , 2.481529  , 1.3545798 , ..., 5.60494   , 1.254172  ,\n",
            "        0.        ]], dtype=float32)], [array([[9.8927772e-01, 1.0722344e-02],\n",
            "       [9.8961848e-01, 1.0381566e-02],\n",
            "       [9.8566717e-01, 1.4332853e-02],\n",
            "       [9.8568624e-01, 1.4313728e-02],\n",
            "       [9.8749512e-01, 1.2504852e-02],\n",
            "       [9.9113339e-01, 8.8666650e-03],\n",
            "       [9.8289466e-01, 1.7105341e-02],\n",
            "       [9.8899555e-01, 1.1004381e-02],\n",
            "       [9.8364627e-01, 1.6353698e-02],\n",
            "       [9.8951310e-01, 1.0486969e-02],\n",
            "       [9.9154633e-01, 8.4536010e-03],\n",
            "       [9.8683006e-01, 1.3169985e-02],\n",
            "       [9.8863322e-01, 1.1366826e-02],\n",
            "       [9.7935063e-01, 2.0649344e-02],\n",
            "       [9.9281693e-01, 7.1830992e-03],\n",
            "       [9.9117380e-01, 8.8262474e-03],\n",
            "       [9.9010849e-01, 9.8915240e-03],\n",
            "       [9.8926920e-01, 1.0730793e-02],\n",
            "       [9.9383318e-01, 6.1668647e-03],\n",
            "       [9.8785770e-01, 1.2142296e-02],\n",
            "       [9.9312168e-01, 6.8782470e-03],\n",
            "       [9.8844391e-01, 1.1556102e-02],\n",
            "       [9.7895354e-01, 2.1046391e-02],\n",
            "       [9.9104732e-01, 8.9526996e-03],\n",
            "       [9.8786396e-01, 1.2136017e-02],\n",
            "       [9.9124616e-01, 8.7537784e-03],\n",
            "       [9.8927516e-01, 1.0724853e-02],\n",
            "       [9.9059415e-01, 9.4058840e-03],\n",
            "       [9.9080843e-01, 9.1915578e-03],\n",
            "       [9.8679113e-01, 1.3208805e-02],\n",
            "       [9.8867291e-01, 1.1327085e-02],\n",
            "       [9.9257702e-01, 7.4229464e-03],\n",
            "       [9.8728961e-01, 1.2710327e-02],\n",
            "       [9.8992378e-01, 1.0076280e-02],\n",
            "       [9.8951310e-01, 1.0486969e-02],\n",
            "       [9.8890078e-01, 1.1099239e-02],\n",
            "       [9.9248391e-01, 7.5161071e-03],\n",
            "       [9.8951310e-01, 1.0486969e-02],\n",
            "       [9.8233485e-01, 1.7665138e-02],\n",
            "       [9.9007893e-01, 9.9211289e-03],\n",
            "       [9.8776966e-01, 1.2230407e-02],\n",
            "       [9.8790854e-01, 1.2091486e-02],\n",
            "       [9.8047996e-01, 1.9520046e-02],\n",
            "       [9.8870403e-01, 1.1295980e-02],\n",
            "       [9.8910463e-01, 1.0895368e-02],\n",
            "       [9.8852044e-01, 1.1479582e-02],\n",
            "       [9.8819369e-01, 1.1806326e-02],\n",
            "       [9.8453587e-01, 1.5464141e-02],\n",
            "       [9.9062192e-01, 9.3781343e-03],\n",
            "       [9.8924595e-01, 1.0754027e-02],\n",
            "       [9.9948370e-01, 5.1629025e-04],\n",
            "       [9.9897707e-01, 1.0229987e-03],\n",
            "       [9.9948394e-01, 5.1600166e-04],\n",
            "       [9.9809092e-01, 1.9091209e-03],\n",
            "       [9.9926847e-01, 7.3152571e-04],\n",
            "       [9.9825674e-01, 1.7432675e-03],\n",
            "       [9.9886501e-01, 1.1350391e-03],\n",
            "       [9.9547172e-01, 4.5283246e-03],\n",
            "       [9.9930799e-01, 6.9199543e-04],\n",
            "       [9.9670500e-01, 3.2949629e-03],\n",
            "       [9.9684709e-01, 3.1529090e-03],\n",
            "       [9.9830663e-01, 1.6934115e-03],\n",
            "       [9.9893075e-01, 1.0692119e-03],\n",
            "       [9.9885738e-01, 1.1426008e-03],\n",
            "       [9.9740607e-01, 2.5939113e-03],\n",
            "       [9.9927038e-01, 7.2964758e-04],\n",
            "       [9.9784374e-01, 2.1562397e-03],\n",
            "       [9.9834716e-01, 1.6528876e-03],\n",
            "       [9.9923396e-01, 7.6598837e-04],\n",
            "       [9.9805367e-01, 1.9463114e-03],\n",
            "       [9.9837792e-01, 1.6220835e-03],\n",
            "       [9.9869066e-01, 1.3093938e-03],\n",
            "       [9.9927765e-01, 7.2230957e-04],\n",
            "       [9.9892056e-01, 1.0794929e-03],\n",
            "       [9.9907327e-01, 9.2666864e-04],\n",
            "       [9.9923003e-01, 7.6998648e-04],\n",
            "       [9.9949479e-01, 5.0524418e-04],\n",
            "       [9.9940562e-01, 5.9436919e-04],\n",
            "       [9.9865842e-01, 1.3416116e-03],\n",
            "       [9.9794227e-01, 2.0577034e-03],\n",
            "       [9.9788886e-01, 2.1111378e-03],\n",
            "       [9.9783164e-01, 2.1683727e-03],\n",
            "       [9.9825066e-01, 1.7493172e-03],\n",
            "       [9.9895310e-01, 1.0468654e-03],\n",
            "       [9.9733388e-01, 2.6661481e-03],\n",
            "       [9.9827397e-01, 1.7259988e-03],\n",
            "       [9.9932778e-01, 6.7223271e-04],\n",
            "       [9.9926215e-01, 7.3781062e-04],\n",
            "       [9.9762207e-01, 2.3779441e-03],\n",
            "       [9.9789160e-01, 2.1084335e-03],\n",
            "       [9.9800509e-01, 1.9949663e-03],\n",
            "       [9.9876827e-01, 1.2316726e-03],\n",
            "       [9.9838245e-01, 1.6175037e-03],\n",
            "       [9.9612159e-01, 3.8783611e-03],\n",
            "       [9.9800962e-01, 1.9904599e-03],\n",
            "       [9.9791783e-01, 2.0821732e-03],\n",
            "       [9.9801934e-01, 1.9806798e-03],\n",
            "       [9.9885762e-01, 1.1423283e-03],\n",
            "       [9.9579740e-01, 4.2026313e-03],\n",
            "       [9.9806482e-01, 1.9352179e-03],\n",
            "       [9.9909949e-01, 9.0052478e-04],\n",
            "       [9.9869138e-01, 1.3086688e-03],\n",
            "       [9.9968648e-01, 3.1351123e-04],\n",
            "       [9.9925429e-01, 7.4567785e-04],\n",
            "       [9.9938917e-01, 6.1084644e-04],\n",
            "       [9.9984574e-01, 1.5419420e-04],\n",
            "       [9.9643898e-01, 3.5610658e-03],\n",
            "       [9.9978453e-01, 2.1552795e-04],\n",
            "       [9.9962032e-01, 3.7966442e-04],\n",
            "       [9.9963367e-01, 3.6626100e-04],\n",
            "       [9.9919981e-01, 8.0020068e-04],\n",
            "       [9.9934262e-01, 6.5738423e-04],\n",
            "       [9.9952257e-01, 4.7745070e-04],\n",
            "       [9.9864358e-01, 1.3563798e-03],\n",
            "       [9.9858439e-01, 1.4156740e-03],\n",
            "       [9.9914503e-01, 8.5498323e-04],\n",
            "       [9.9935013e-01, 6.4986577e-04],\n",
            "       [9.9979812e-01, 2.0193413e-04],\n",
            "       [9.9988937e-01, 1.1064431e-04],\n",
            "       [9.9916553e-01, 8.3451677e-04],\n",
            "       [9.9954611e-01, 4.5391728e-04],\n",
            "       [9.9820423e-01, 1.7957577e-03],\n",
            "       [9.9987805e-01, 1.2192251e-04],\n",
            "       [9.9919361e-01, 8.0638676e-04],\n",
            "       [9.9941409e-01, 5.8592128e-04],\n",
            "       [9.9969971e-01, 3.0032475e-04],\n",
            "       [9.9903321e-01, 9.6675981e-04],\n",
            "       [9.9884230e-01, 1.1577632e-03],\n",
            "       [9.9935526e-01, 6.4480345e-04],\n",
            "       [9.9971598e-01, 2.8402440e-04],\n",
            "       [9.9980539e-01, 1.9467779e-04],\n",
            "       [9.9982506e-01, 1.7491069e-04],\n",
            "       [9.9935287e-01, 6.4710370e-04],\n",
            "       [9.9920303e-01, 7.9697446e-04],\n",
            "       [9.9921668e-01, 7.8330853e-04],\n",
            "       [9.9984145e-01, 1.5853414e-04],\n",
            "       [9.9902332e-01, 9.7672117e-04],\n",
            "       [9.9924040e-01, 7.5960328e-04],\n",
            "       [9.9867934e-01, 1.3206468e-03],\n",
            "       [9.9953723e-01, 4.6277451e-04],\n",
            "       [9.9945003e-01, 5.4994342e-04],\n",
            "       [9.9949706e-01, 5.0297665e-04],\n",
            "       [9.9869138e-01, 1.3086688e-03],\n",
            "       [9.9952018e-01, 4.7984743e-04],\n",
            "       [9.9940562e-01, 5.9432950e-04],\n",
            "       [9.9942291e-01, 5.7714485e-04],\n",
            "       [9.9928576e-01, 7.1430713e-04],\n",
            "       [9.9929368e-01, 7.0630730e-04],\n",
            "       [9.9886131e-01, 1.1387364e-03],\n",
            "       [9.9863893e-01, 1.3610506e-03]], dtype=float32)], [array([[0.80197906, 0.8583581 , 0.25289223],\n",
            "       [0.8022731 , 0.8588732 , 0.25289294],\n",
            "       [0.7988639 , 0.8529007 , 0.25288475],\n",
            "       [0.7988803 , 0.8529296 , 0.25288478],\n",
            "       [0.8004411 , 0.8556638 , 0.25288853],\n",
            "       [0.8035802 , 0.861163  , 0.25289607],\n",
            "       [0.7964717 , 0.84871   , 0.252879  ],\n",
            "       [0.8017357 , 0.8579317 , 0.25289166],\n",
            "       [0.7971202 , 0.8498461 , 0.25288057],\n",
            "       [0.80218214, 0.85871387, 0.25289273],\n",
            "       [0.8039365 , 0.86178726, 0.25289693],\n",
            "       [0.79986715, 0.8546584 , 0.25288716],\n",
            "       [0.801423  , 0.85738397, 0.25289088],\n",
            "       [0.7934138 , 0.84335315, 0.25287166],\n",
            "       [0.8050328 , 0.8637077 , 0.2528996 ],\n",
            "       [0.8036151 , 0.86122406, 0.25289616],\n",
            "       [0.80269593, 0.85961384, 0.25289395],\n",
            "       [0.80197173, 0.85834527, 0.25289223],\n",
            "       [0.8059096 , 0.8652438 , 0.25290167],\n",
            "       [0.8007539 , 0.8562118 , 0.2528893 ],\n",
            "       [0.8052957 , 0.8641684 , 0.2529002 ],\n",
            "       [0.8012597 , 0.8570978 , 0.2528905 ],\n",
            "       [0.7930712 , 0.84275293, 0.25287083],\n",
            "       [0.80350596, 0.86103296, 0.2528959 ],\n",
            "       [0.80075926, 0.8562212 , 0.2528893 ],\n",
            "       [0.8036775 , 0.86133355, 0.2528963 ],\n",
            "       [0.8019769 , 0.85835433, 0.25289223],\n",
            "       [0.8031149 , 0.8603479 , 0.25289497],\n",
            "       [0.8032998 , 0.8606718 , 0.2528954 ],\n",
            "       [0.79983366, 0.85459965, 0.25288707],\n",
            "       [0.8014572 , 0.857444  , 0.25289097],\n",
            "       [0.8048258 , 0.86334515, 0.25289908],\n",
            "       [0.8002637 , 0.8553532 , 0.2528881 ],\n",
            "       [0.8025365 , 0.8593346 , 0.25289357],\n",
            "       [0.80218214, 0.85871387, 0.25289273],\n",
            "       [0.80165386, 0.8577884 , 0.25289145],\n",
            "       [0.8047455 , 0.86320436, 0.25289887],\n",
            "       [0.80218214, 0.85871387, 0.25289273],\n",
            "       [0.7959887 , 0.84786385, 0.25287783],\n",
            "       [0.80267036, 0.85956913, 0.2528939 ],\n",
            "       [0.8006779 , 0.8560786 , 0.2528891 ],\n",
            "       [0.80079776, 0.8562886 , 0.2528894 ],\n",
            "       [0.79438823, 0.8450601 , 0.252874  ],\n",
            "       [0.8014841 , 0.857491  , 0.25289103],\n",
            "       [0.80182976, 0.85809654, 0.25289187],\n",
            "       [0.8013257 , 0.8572135 , 0.25289068],\n",
            "       [0.8010438 , 0.8567196 , 0.25289   ],\n",
            "       [0.79788774, 0.85119075, 0.2528824 ],\n",
            "       [0.80313885, 0.8603899 , 0.25289503],\n",
            "       [0.8019517 , 0.85831016, 0.25289217],\n",
            "       [0.81078506, 0.8737847 , 0.2529134 ],\n",
            "       [0.81034786, 0.87301886, 0.25291234],\n",
            "       [0.81078523, 0.87378514, 0.2529134 ],\n",
            "       [0.80958325, 0.8716795 , 0.2529105 ],\n",
            "       [0.8105993 , 0.8734594 , 0.25291294],\n",
            "       [0.8097264 , 0.8719302 , 0.25291085],\n",
            "       [0.8102512 , 0.8728495 , 0.2529121 ],\n",
            "       [0.8073234 , 0.8677205 , 0.25290507],\n",
            "       [0.8106334 , 0.8735191 , 0.25291303],\n",
            "       [0.8083875 , 0.8695847 , 0.25290763],\n",
            "       [0.80851007, 0.86979944, 0.25290793],\n",
            "       [0.8097694 , 0.8720055 , 0.25291094],\n",
            "       [0.8103079 , 0.87294894, 0.25291225],\n",
            "       [0.8102446 , 0.872838  , 0.2529121 ],\n",
            "       [0.8089924 , 0.8706444 , 0.2529091 ],\n",
            "       [0.81060094, 0.87346226, 0.25291294],\n",
            "       [0.80937004, 0.87130594, 0.25291   ],\n",
            "       [0.8098044 , 0.8720668 , 0.25291103],\n",
            "       [0.8105696 , 0.8734073 , 0.25291288],\n",
            "       [0.8095512 , 0.8716232 , 0.25291044],\n",
            "       [0.8098309 , 0.8721133 , 0.2529111 ],\n",
            "       [0.8101008 , 0.87258595, 0.25291175],\n",
            "       [0.81060725, 0.8734733 , 0.25291297],\n",
            "       [0.8102991 , 0.8729335 , 0.25291222],\n",
            "       [0.8104309 , 0.8731644 , 0.25291255],\n",
            "       [0.8105661 , 0.8734013 , 0.25291288],\n",
            "       [0.8107946 , 0.87380147, 0.25291342],\n",
            "       [0.81071764, 0.8736667 , 0.25291324],\n",
            "       [0.81007296, 0.8725373 , 0.2529117 ],\n",
            "       [0.80945504, 0.87145483, 0.2529102 ],\n",
            "       [0.8094089 , 0.8713741 , 0.25291008],\n",
            "       [0.80935955, 0.8712876 , 0.25290996],\n",
            "       [0.8097211 , 0.87192094, 0.25291085],\n",
            "       [0.81032723, 0.87298274, 0.25291228],\n",
            "       [0.8089301 , 0.8705352 , 0.25290895],\n",
            "       [0.80974126, 0.8719562 , 0.25291088],\n",
            "       [0.81065047, 0.87354904, 0.25291306],\n",
            "       [0.81059384, 0.8734499 , 0.25291294],\n",
            "       [0.80917877, 0.87097085, 0.25290954],\n",
            "       [0.80941135, 0.87137824, 0.2529101 ],\n",
            "       [0.8095093 , 0.8715497 , 0.25291032],\n",
            "       [0.8101678 , 0.8727034 , 0.2529119 ],\n",
            "       [0.80983484, 0.8721202 , 0.25291112],\n",
            "       [0.8078841 , 0.8687029 , 0.2529064 ],\n",
            "       [0.80951315, 0.8715566 , 0.25291035],\n",
            "       [0.809434  , 0.8714179 , 0.25291014],\n",
            "       [0.8095215 , 0.8715713 , 0.25291035],\n",
            "       [0.8102448 , 0.87283844, 0.2529121 ],\n",
            "       [0.80760443, 0.86821276, 0.25290576],\n",
            "       [0.8095608 , 0.87164   , 0.25291047],\n",
            "       [0.8104535 , 0.873204  , 0.2529126 ],\n",
            "       [0.8101014 , 0.872587  , 0.25291175],\n",
            "       [0.81096   , 0.8740912 , 0.2529138 ],\n",
            "       [0.8105871 , 0.873438  , 0.2529129 ],\n",
            "       [0.8107034 , 0.87364185, 0.2529132 ],\n",
            "       [0.81109744, 0.874332  , 0.25291413],\n",
            "       [0.8081579 , 0.8691825 , 0.2529071 ],\n",
            "       [0.8110446 , 0.8742394 , 0.252914  ],\n",
            "       [0.81090283, 0.8739912 , 0.25291368],\n",
            "       [0.8109144 , 0.8740115 , 0.2529137 ],\n",
            "       [0.8105401 , 0.8733556 , 0.25291282],\n",
            "       [0.8106633 , 0.8735715 , 0.2529131 ],\n",
            "       [0.81081855, 0.87384343, 0.25291348],\n",
            "       [0.81006014, 0.8725149 , 0.25291166],\n",
            "       [0.81000906, 0.8724253 , 0.25291154],\n",
            "       [0.8104928 , 0.87327284, 0.2529127 ],\n",
            "       [0.8106698 , 0.87358284, 0.25291312],\n",
            "       [0.81105626, 0.87425995, 0.25291404],\n",
            "       [0.81113505, 0.8743979 , 0.25291425],\n",
            "       [0.81051046, 0.8733038 , 0.25291273],\n",
            "       [0.8108388 , 0.873879  , 0.25291353],\n",
            "       [0.80968106, 0.8718508 , 0.25291073],\n",
            "       [0.8111253 , 0.8743808 , 0.25291422],\n",
            "       [0.8105347 , 0.87334627, 0.2529128 ],\n",
            "       [0.8107249 , 0.87367946, 0.25291324],\n",
            "       [0.8109714 , 0.8741112 , 0.25291383],\n",
            "       [0.8103963 , 0.8731038 , 0.25291246],\n",
            "       [0.81023157, 0.87281513, 0.25291207],\n",
            "       [0.8106742 , 0.8735905 , 0.25291312],\n",
            "       [0.81098545, 0.8741358 , 0.25291386],\n",
            "       [0.8110625 , 0.8742709 , 0.25291407],\n",
            "       [0.81107956, 0.8743007 , 0.2529141 ],\n",
            "       [0.8106721 , 0.873587  , 0.25291312],\n",
            "       [0.8105428 , 0.8733605 , 0.25291282],\n",
            "       [0.8105546 , 0.8733811 , 0.25291285],\n",
            "       [0.8110937 , 0.87432545, 0.25291413],\n",
            "       [0.81038773, 0.87308884, 0.25291243],\n",
            "       [0.8105751 , 0.87341696, 0.25291288],\n",
            "       [0.810091  , 0.8725689 , 0.25291172],\n",
            "       [0.8108312 , 0.8738656 , 0.2529135 ],\n",
            "       [0.81075597, 0.8737338 , 0.25291333],\n",
            "       [0.8107965 , 0.87380487, 0.25291342],\n",
            "       [0.8101014 , 0.872587  , 0.25291175],\n",
            "       [0.81081647, 0.8738398 , 0.25291348],\n",
            "       [0.81071764, 0.87366676, 0.25291324],\n",
            "       [0.81073254, 0.8736928 , 0.25291327],\n",
            "       [0.8106142 , 0.87348545, 0.252913  ],\n",
            "       [0.8106211 , 0.8734975 , 0.252913  ],\n",
            "       [0.810248  , 0.8728439 , 0.2529121 ],\n",
            "       [0.81005615, 0.87250787, 0.25291163]], dtype=float32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu1VTz_CAh8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "882c1574-6b43-4fe2-bfa5-190051bf9d65"
      },
      "source": [
        "# training=False is needed only if there are layers with different\n",
        "# behavior during training versus inference (e.g. Dropout).\n",
        "#predictions = model(outputs, training=False)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example 0 prediction: Iris versicolor (40.1%)\n",
            "Example 1 prediction: Iris versicolor (40.2%)\n",
            "Example 2 prediction: Iris versicolor (40.1%)\n",
            "Example 3 prediction: Iris versicolor (40.1%)\n",
            "Example 4 prediction: Iris versicolor (40.1%)\n",
            "Example 5 prediction: Iris versicolor (40.2%)\n",
            "Example 6 prediction: Iris versicolor (40.0%)\n",
            "Example 7 prediction: Iris versicolor (40.1%)\n",
            "Example 8 prediction: Iris versicolor (40.0%)\n",
            "Example 9 prediction: Iris versicolor (40.1%)\n",
            "Example 10 prediction: Iris versicolor (40.2%)\n",
            "Example 11 prediction: Iris versicolor (40.1%)\n",
            "Example 12 prediction: Iris versicolor (40.1%)\n",
            "Example 13 prediction: Iris versicolor (39.9%)\n",
            "Example 14 prediction: Iris versicolor (40.2%)\n",
            "Example 15 prediction: Iris versicolor (40.2%)\n",
            "Example 16 prediction: Iris versicolor (40.2%)\n",
            "Example 17 prediction: Iris versicolor (40.1%)\n",
            "Example 18 prediction: Iris versicolor (40.3%)\n",
            "Example 19 prediction: Iris versicolor (40.1%)\n",
            "Example 20 prediction: Iris versicolor (40.2%)\n",
            "Example 21 prediction: Iris versicolor (40.1%)\n",
            "Example 22 prediction: Iris versicolor (39.9%)\n",
            "Example 23 prediction: Iris versicolor (40.2%)\n",
            "Example 24 prediction: Iris versicolor (40.1%)\n",
            "Example 25 prediction: Iris versicolor (40.2%)\n",
            "Example 26 prediction: Iris versicolor (40.1%)\n",
            "Example 27 prediction: Iris versicolor (40.2%)\n",
            "Example 28 prediction: Iris versicolor (40.2%)\n",
            "Example 29 prediction: Iris versicolor (40.1%)\n",
            "Example 30 prediction: Iris versicolor (40.1%)\n",
            "Example 31 prediction: Iris versicolor (40.2%)\n",
            "Example 32 prediction: Iris versicolor (40.1%)\n",
            "Example 33 prediction: Iris versicolor (40.2%)\n",
            "Example 34 prediction: Iris versicolor (40.1%)\n",
            "Example 35 prediction: Iris versicolor (40.1%)\n",
            "Example 36 prediction: Iris versicolor (40.2%)\n",
            "Example 37 prediction: Iris versicolor (40.1%)\n",
            "Example 38 prediction: Iris versicolor (40.0%)\n",
            "Example 39 prediction: Iris versicolor (40.2%)\n",
            "Example 40 prediction: Iris versicolor (40.1%)\n",
            "Example 41 prediction: Iris versicolor (40.1%)\n",
            "Example 42 prediction: Iris versicolor (39.9%)\n",
            "Example 43 prediction: Iris versicolor (40.1%)\n",
            "Example 44 prediction: Iris versicolor (40.1%)\n",
            "Example 45 prediction: Iris versicolor (40.1%)\n",
            "Example 46 prediction: Iris versicolor (40.1%)\n",
            "Example 47 prediction: Iris versicolor (40.0%)\n",
            "Example 48 prediction: Iris versicolor (40.2%)\n",
            "Example 49 prediction: Iris versicolor (40.1%)\n",
            "Example 50 prediction: Iris versicolor (40.4%)\n",
            "Example 51 prediction: Iris versicolor (40.4%)\n",
            "Example 52 prediction: Iris versicolor (40.4%)\n",
            "Example 53 prediction: Iris versicolor (40.3%)\n",
            "Example 54 prediction: Iris versicolor (40.4%)\n",
            "Example 55 prediction: Iris versicolor (40.4%)\n",
            "Example 56 prediction: Iris versicolor (40.4%)\n",
            "Example 57 prediction: Iris versicolor (40.3%)\n",
            "Example 58 prediction: Iris versicolor (40.4%)\n",
            "Example 59 prediction: Iris versicolor (40.3%)\n",
            "Example 60 prediction: Iris versicolor (40.3%)\n",
            "Example 61 prediction: Iris versicolor (40.4%)\n",
            "Example 62 prediction: Iris versicolor (40.4%)\n",
            "Example 63 prediction: Iris versicolor (40.4%)\n",
            "Example 64 prediction: Iris versicolor (40.3%)\n",
            "Example 65 prediction: Iris versicolor (40.4%)\n",
            "Example 66 prediction: Iris versicolor (40.3%)\n",
            "Example 67 prediction: Iris versicolor (40.4%)\n",
            "Example 68 prediction: Iris versicolor (40.4%)\n",
            "Example 69 prediction: Iris versicolor (40.3%)\n",
            "Example 70 prediction: Iris versicolor (40.4%)\n",
            "Example 71 prediction: Iris versicolor (40.4%)\n",
            "Example 72 prediction: Iris versicolor (40.4%)\n",
            "Example 73 prediction: Iris versicolor (40.4%)\n",
            "Example 74 prediction: Iris versicolor (40.4%)\n",
            "Example 75 prediction: Iris versicolor (40.4%)\n",
            "Example 76 prediction: Iris versicolor (40.4%)\n",
            "Example 77 prediction: Iris versicolor (40.4%)\n",
            "Example 78 prediction: Iris versicolor (40.4%)\n",
            "Example 79 prediction: Iris versicolor (40.3%)\n",
            "Example 80 prediction: Iris versicolor (40.3%)\n",
            "Example 81 prediction: Iris versicolor (40.3%)\n",
            "Example 82 prediction: Iris versicolor (40.4%)\n",
            "Example 83 prediction: Iris versicolor (40.4%)\n",
            "Example 84 prediction: Iris versicolor (40.3%)\n",
            "Example 85 prediction: Iris versicolor (40.4%)\n",
            "Example 86 prediction: Iris versicolor (40.4%)\n",
            "Example 87 prediction: Iris versicolor (40.4%)\n",
            "Example 88 prediction: Iris versicolor (40.3%)\n",
            "Example 89 prediction: Iris versicolor (40.3%)\n",
            "Example 90 prediction: Iris versicolor (40.3%)\n",
            "Example 91 prediction: Iris versicolor (40.4%)\n",
            "Example 92 prediction: Iris versicolor (40.4%)\n",
            "Example 93 prediction: Iris versicolor (40.3%)\n",
            "Example 94 prediction: Iris versicolor (40.3%)\n",
            "Example 95 prediction: Iris versicolor (40.3%)\n",
            "Example 96 prediction: Iris versicolor (40.3%)\n",
            "Example 97 prediction: Iris versicolor (40.4%)\n",
            "Example 98 prediction: Iris versicolor (40.3%)\n",
            "Example 99 prediction: Iris versicolor (40.3%)\n",
            "Example 100 prediction: Iris versicolor (40.4%)\n",
            "Example 101 prediction: Iris versicolor (40.4%)\n",
            "Example 102 prediction: Iris versicolor (40.4%)\n",
            "Example 103 prediction: Iris versicolor (40.4%)\n",
            "Example 104 prediction: Iris versicolor (40.4%)\n",
            "Example 105 prediction: Iris versicolor (40.4%)\n",
            "Example 106 prediction: Iris versicolor (40.3%)\n",
            "Example 107 prediction: Iris versicolor (40.4%)\n",
            "Example 108 prediction: Iris versicolor (40.4%)\n",
            "Example 109 prediction: Iris versicolor (40.4%)\n",
            "Example 110 prediction: Iris versicolor (40.4%)\n",
            "Example 111 prediction: Iris versicolor (40.4%)\n",
            "Example 112 prediction: Iris versicolor (40.4%)\n",
            "Example 113 prediction: Iris versicolor (40.4%)\n",
            "Example 114 prediction: Iris versicolor (40.4%)\n",
            "Example 115 prediction: Iris versicolor (40.4%)\n",
            "Example 116 prediction: Iris versicolor (40.4%)\n",
            "Example 117 prediction: Iris versicolor (40.4%)\n",
            "Example 118 prediction: Iris versicolor (40.4%)\n",
            "Example 119 prediction: Iris versicolor (40.4%)\n",
            "Example 120 prediction: Iris versicolor (40.4%)\n",
            "Example 121 prediction: Iris versicolor (40.4%)\n",
            "Example 122 prediction: Iris versicolor (40.4%)\n",
            "Example 123 prediction: Iris versicolor (40.4%)\n",
            "Example 124 prediction: Iris versicolor (40.4%)\n",
            "Example 125 prediction: Iris versicolor (40.4%)\n",
            "Example 126 prediction: Iris versicolor (40.4%)\n",
            "Example 127 prediction: Iris versicolor (40.4%)\n",
            "Example 128 prediction: Iris versicolor (40.4%)\n",
            "Example 129 prediction: Iris versicolor (40.4%)\n",
            "Example 130 prediction: Iris versicolor (40.4%)\n",
            "Example 131 prediction: Iris versicolor (40.4%)\n",
            "Example 132 prediction: Iris versicolor (40.4%)\n",
            "Example 133 prediction: Iris versicolor (40.4%)\n",
            "Example 134 prediction: Iris versicolor (40.4%)\n",
            "Example 135 prediction: Iris versicolor (40.4%)\n",
            "Example 136 prediction: Iris versicolor (40.4%)\n",
            "Example 137 prediction: Iris versicolor (40.4%)\n",
            "Example 138 prediction: Iris versicolor (40.4%)\n",
            "Example 139 prediction: Iris versicolor (40.4%)\n",
            "Example 140 prediction: Iris versicolor (40.4%)\n",
            "Example 141 prediction: Iris versicolor (40.4%)\n",
            "Example 142 prediction: Iris versicolor (40.4%)\n",
            "Example 143 prediction: Iris versicolor (40.4%)\n",
            "Example 144 prediction: Iris versicolor (40.4%)\n",
            "Example 145 prediction: Iris versicolor (40.4%)\n",
            "Example 146 prediction: Iris versicolor (40.4%)\n",
            "Example 147 prediction: Iris versicolor (40.4%)\n",
            "Example 148 prediction: Iris versicolor (40.4%)\n",
            "Example 149 prediction: Iris versicolor (40.4%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}